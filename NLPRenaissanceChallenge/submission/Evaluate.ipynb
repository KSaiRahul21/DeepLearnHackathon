{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c826f7fa-d701-4778-9fb7-b5da672cbe1d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c826f7fa-d701-4778-9fb7-b5da672cbe1d",
        "outputId": "7f29ecbd-7100-49fb-c417-d56d4e5dd4f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.25.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting Levenshtein==0.25.1 (from python-Levenshtein)\n",
            "  Downloading Levenshtein-0.25.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.8.0 (from Levenshtein==0.25.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.9.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading python_Levenshtein-0.25.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading Levenshtein-0.25.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n",
            "Downloading rapidfuzz-3.9.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.25.1 python-Levenshtein-0.25.1 rapidfuzz-3.9.7\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting datasets>=2.0.0 (from evaluate)\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/scs_deal_learning/miniconda_env/envs/deeplearn_env/lib/python3.8/site-packages (from evaluate) (1.23.5)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /home/scs_deal_learning/miniconda_env/envs/deeplearn_env/lib/python3.8/site-packages (from evaluate) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /home/scs_deal_learning/miniconda_env/envs/deeplearn_env/lib/python3.8/site-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /home/scs_deal_learning/miniconda_env/envs/deeplearn_env/lib/python3.8/site-packages (from evaluate) (4.67.1)\n",
            "Collecting xxhash (from evaluate)\n",
            "  Downloading xxhash-3.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.18-py38-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /home/scs_deal_learning/miniconda_env/envs/deeplearn_env/lib/python3.8/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Collecting huggingface-hub>=0.7.0 (from evaluate)\n",
            "  Downloading huggingface_hub-0.33.4-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: packaging in /home/scs_deal_learning/miniconda_env/envs/deeplearn_env/lib/python3.8/site-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /home/scs_deal_learning/miniconda_env/envs/deeplearn_env/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Collecting pyarrow>=15.0.0 (from datasets>=2.0.0->evaluate)\n",
            "  Downloading pyarrow-17.0.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.16-py38-none-any.whl.metadata (7.1 kB)\n",
            "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting aiohttp (from datasets>=2.0.0->evaluate)\n",
            "  Downloading aiohttp-3.10.11-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting pyyaml>=5.1 (from datasets>=2.0.0->evaluate)\n",
            "  Downloading PyYAML-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/scs_deal_learning/miniconda_env/envs/deeplearn_env/lib/python3.8/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub>=0.7.0->evaluate)\n",
            "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/scs_deal_learning/miniconda_env/envs/deeplearn_env/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/scs_deal_learning/miniconda_env/envs/deeplearn_env/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/scs_deal_learning/miniconda_env/envs/deeplearn_env/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/scs_deal_learning/miniconda_env/envs/deeplearn_env/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (2025.7.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/scs_deal_learning/miniconda_env/envs/deeplearn_env/lib/python3.8/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/scs_deal_learning/miniconda_env/envs/deeplearn_env/lib/python3.8/site-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/scs_deal_learning/miniconda_env/envs/deeplearn_env/lib/python3.8/site-packages (from pandas->evaluate) (2025.2)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
            "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.0.0->evaluate)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.0.0->evaluate)\n",
            "  Downloading frozenlist-1.5.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->evaluate)\n",
            "  Downloading multidict-6.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting yarl<2.0,>=1.12.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
            "  Downloading yarl-1.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: six>=1.5 in /home/scs_deal_learning/miniconda_env/envs/deeplearn_env/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate)\n",
            "  Downloading propcache-0.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "Downloading huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\n",
            "Downloading multiprocess-0.70.16-py38-none-any.whl (132 kB)\n",
            "Downloading xxhash-3.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "Downloading aiohttp-3.10.11-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp38-cp38-manylinux_2_28_x86_64.whl (40.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (746 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m746.5/746.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
            "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Downloading frozenlist-1.5.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (243 kB)\n",
            "Downloading multidict-6.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "Downloading yarl-1.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
            "Downloading propcache-0.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "Installing collected packages: xxhash, pyyaml, pyarrow, propcache, multidict, hf-xet, fsspec, frozenlist, dill, attrs, async-timeout, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets, evaluate\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.4.1 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohappyeyeballs-2.4.4 aiohttp-3.10.11 aiosignal-1.3.1 async-timeout-5.0.1 attrs-25.3.0 datasets-3.1.0 dill-0.3.8 evaluate-0.4.5 frozenlist-1.5.0 fsspec-2024.9.0 hf-xet-1.1.5 huggingface-hub-0.33.4 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.0 pyarrow-17.0.0 pyyaml-6.0.2 xxhash-3.5.0 yarl-1.15.2\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting click>=8.1.8 (from jiwer)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rapidfuzz>=3.9.7 in /home/scs_deal_learning/miniconda_env/envs/deeplearn_env/lib/python3.8/site-packages (from jiwer) (3.9.7)\n",
            "Downloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
            "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Installing collected packages: click, jiwer\n",
            "Successfully installed click-8.1.8 jiwer-4.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install python-Levenshtein\n",
        "!pip install evaluate\n",
        "!pip install jiwer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3cd7d03f-2732-4215-8e4d-7ee7b49eb3be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "dc713efb6db5411aa1b8dd8877ee1fcc",
            "554720a814cc466a8e281fcb02d8a28a"
          ]
        },
        "id": "3cd7d03f-2732-4215-8e4d-7ee7b49eb3be",
        "outputId": "0d1e2582-e3d2-41f0-afe9-3e1354ef1c9d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/scs_deal_learning/miniconda_env/envs/deeplearn_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Downloading builder script: 6.61kB [00:00, 11.8MB/s]\n",
            "Downloading builder script: 5.13kB [00:00, 3.54MB/s]\n"
          ]
        }
      ],
      "source": [
        "from evaluate import load\n",
        "from Levenshtein import distance as levenshtein_distance\n",
        "from difflib import SequenceMatcher\n",
        "# import Levenshtein\n",
        "\n",
        "cer_metric = load(\"cer\")\n",
        "wer_metric = load(\"wer\")\n",
        "\n",
        "def compute_metrics(predicted_text, reference_text):\n",
        "    \"\"\"\n",
        "    Compute various text similarity metrics between predicted and reference text.\n",
        "\n",
        "    Args:\n",
        "        predicted_text (str or list): The predicted text(s)\n",
        "        reference_text (str or list): The reference/ground truth text(s)\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing metrics\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert single strings to lists\n",
        "    if isinstance(predicted_text, str):\n",
        "        predicted_text = [predicted_text]\n",
        "    if isinstance(reference_text, str):\n",
        "        reference_text = [reference_text]\n",
        "\n",
        "    # Compute CER and WER\n",
        "    cer_score = cer_metric.compute(predictions=predicted_text, references=reference_text)\n",
        "    wer_score = wer_metric.compute(predictions=predicted_text, references=reference_text)\n",
        "\n",
        "    # Levenshtein distance\n",
        "    lev_dist = levenshtein_distance(predicted_text[0], reference_text[0])\n",
        "    # similarity = Levenshtein.ratio(predicted_text[0], reference_text[0])\n",
        "\n",
        "    # Similarity score (0-1)\n",
        "    seq_matcher = SequenceMatcher(None, predicted_text[0], reference_text[0])\n",
        "    similarity = seq_matcher.ratio()\n",
        "\n",
        "    return {\n",
        "        \"cer\": cer_score,\n",
        "        \"wer\": wer_score,\n",
        "        \"levenshtein_distance\": lev_dist,\n",
        "        \"similarity_score\": similarity,\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c5ab78fd-403a-4bba-aeb5-6fc8b398e382",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5ab78fd-403a-4bba-aeb5-6fc8b398e382",
        "outputId": "b82fdcae-5c08-44b8-fcd4-8422ba580bad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'cer': 0.0, 'wer': 0.0, 'levenshtein_distance': 0, 'similarity_score': 1.0}\n"
          ]
        }
      ],
      "source": [
        "reference = 'matar'\n",
        "\n",
        "\n",
        "# predicted = 'matar al enemigs que debia precaverfé, aurique le halle inerme, indefensa'\n",
        "predicted = 'matar'\n",
        "\n",
        "result = compute_metrics(predicted,reference)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3b25bae8-d17d-4ba4-a3f3-c4c173b7f20d",
      "metadata": {
        "id": "3b25bae8-d17d-4ba4-a3f3-c4c173b7f20d"
      },
      "outputs": [],
      "source": [
        "from evaluate import load\n",
        "from Levenshtein import distance as levenshtein_distance\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "cer_metric = load(\"cer\")\n",
        "wer_metric = load(\"wer\")\n",
        "\n",
        "def compute_metrics(predicted_text, reference_text):\n",
        "    \"\"\"\n",
        "    Compute various text similarity metrics between predicted and reference text.\n",
        "\n",
        "    Args:\n",
        "        predicted_text (str or list): The predicted text(s)\n",
        "        reference_text (str or list): The reference/ground truth text(s)\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing metrics\n",
        "    \"\"\"\n",
        "\n",
        "    if isinstance(predicted_text, str):\n",
        "        predicted_text = [predicted_text]\n",
        "    if isinstance(reference_text, str):\n",
        "        reference_text = [reference_text]\n",
        "\n",
        "    # Compute CER and WER\n",
        "    cer_score = cer_metric.compute(predictions=predicted_text, references=reference_text)\n",
        "    wer_score = wer_metric.compute(predictions=predicted_text, references=reference_text)\n",
        "\n",
        "    levenshtein_distances = []\n",
        "    similarity_scores = []\n",
        "    for pred, ref in zip(predicted_text, reference_text):\n",
        "\n",
        "        # Levenshtein distance\n",
        "        lev_dist = levenshtein_distance(pred, ref)\n",
        "        levenshtein_distances.append(lev_dist)\n",
        "\n",
        "        # Similarity score (0-1)\n",
        "        seq_matcher = SequenceMatcher(None, pred, ref)\n",
        "        similarity = seq_matcher.ratio()\n",
        "        similarity_scores.append(similarity)\n",
        "\n",
        "    # Calculate averages if multiple samples\n",
        "    avg_lev_dist = sum(levenshtein_distances) / len(levenshtein_distances)\n",
        "    avg_similarity = sum(similarity_scores) / len(similarity_scores)\n",
        "\n",
        "    return {\n",
        "        \"cer\": cer_score,\n",
        "        \"wer\": wer_score,\n",
        "        \"levenshtein_distance\": avg_lev_dist,\n",
        "        \"similarity_score\": avg_similarity,\n",
        "        \"all_levenshtein_distances\": levenshtein_distances,\n",
        "        \"all_similarity_scores\": similarity_scores\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6648efa0-40e2-43e4-aa11-8a4d5f249759",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6648efa0-40e2-43e4-aa11-8a4d5f249759",
        "outputId": "00e5dbd3-9925-4503-829c-3b8bedbf8c30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'cer': 0.8333333333333334, 'wer': 0.5, 'levenshtein_distance': 2.5, 'similarity_score': 0.5, 'all_levenshtein_distances': [5, 0], 'all_similarity_scores': [0.0, 1.0]}\n"
          ]
        }
      ],
      "source": [
        "reference = ['matar',\n",
        "             'ô']\n",
        "\n",
        "# predicted = ['matar al enemigs que debia precaverfé, aurique le halle inerme, indefensa',\n",
        "#              'ô fe le acometa feguto, è por por la elpalda, ô con arma de luego,ô con ve-']\n",
        "\n",
        "predicted = ['',\n",
        "             'ô']\n",
        "\n",
        "result = compute_metrics(predicted,reference)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "feba99d5",
      "metadata": {
        "id": "feba99d5"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def evaluate_submission(submission_json_path, label_json_path):\n",
        "    \"\"\"\n",
        "    Evaluates the actual submission files against the corresponding label files.\n",
        "\n",
        "    The submission file is a JSON file with the following structure:\n",
        "    {\"file_path\": [xxx, yyy, ...], \"prediction\": [xxx, yyy, ...]}\n",
        "    'file_path' represents the file paths of the data in the target dataset.\n",
        "    'prediction' represents the output strings from the participant's model.\n",
        "\n",
        "    The label file is also a JSON file with the following structure:\n",
        "    {\"file_path\": [xxx, yyy, ...], \"label\": [xxx, yyy, ...]}\n",
        "    'file_path' represents the file paths of the data in the target dataset.\n",
        "    'label' represents the ground truth strings for the data.\n",
        "    \"\"\"\n",
        "    with open(submission_json_path, 'r') as f:\n",
        "        submission = json.load(f)\n",
        "\n",
        "    with open(label_json_path, 'r') as f:\n",
        "        labels = json.load(f)\n",
        "\n",
        "    # Create dictionaries for easier lookup by file_path\n",
        "    submission_dict = dict(zip(submission['file_path'], submission['prediction']))\n",
        "    labels_dict = dict(zip(labels['file_path'], labels['label']))\n",
        "\n",
        "    # Align predictions and references based on file_path\n",
        "    predictions = []\n",
        "    references = []\n",
        "    for file_path in labels['file_path']:\n",
        "        if file_path in submission_dict:\n",
        "            predictions.append(submission_dict[file_path].lower())\n",
        "            references.append(labels_dict[file_path].lower())\n",
        "        else:\n",
        "            # Handle cases where a file_path in labels is not in submission\n",
        "            print(f\"Warning: File path '{file_path}' not found in submission file.\")\n",
        "            predictions.append(\"\")\n",
        "            references.append(labels_dict[file_path])\n",
        "\n",
        "\n",
        "    # Compute metrics using the existing compute_metrics function\n",
        "    results = compute_metrics(predictions, references)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3xXW7zUmgWD7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xXW7zUmgWD7",
        "outputId": "776cbc8d-dff2-448e-a076-c52ed815ab99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'cer': 0.052083333333333336, 'wer': 0.2631578947368421, 'levenshtein_distance': 1.6666666666666667, 'similarity_score': 0.9527478171545969, 'all_levenshtein_distances': [2, 3, 0], 'all_similarity_scores': [0.9491525423728814, 0.9090909090909091, 1.0]}\n"
          ]
        }
      ],
      "source": [
        "label = {\n",
        "    'file_path' : ['book1_page1','book1_page2','book2_page1'],\n",
        "    'label' : [\n",
        "        \"SI POR evitar UN pecado mortal\",\n",
        "        \"aveys de poner vuestra vida en pe\",\n",
        "        \"ligro arriesgalda QUE es el mejor\",\n",
        "    ]\n",
        "}\n",
        "\n",
        "label_object = json.dumps(label, indent=4)\n",
        "save_path = 'label.json'\n",
        "with open(save_path, 'w') as f:\n",
        "    f.write(label_object)\n",
        "\n",
        "submission = {\n",
        "    'file_path' : ['book1_page1','book1_page2','book2_page1'],\n",
        "    'prediction' : [\n",
        "        \"Si por euitar n pecado mortal\",\n",
        "        \"aueys de poner uuestra uida en pe\",\n",
        "        \"ligro arriesgalda que es el mejor\",\n",
        "    ]\n",
        "\n",
        "}\n",
        "\n",
        "submission_object = json.dumps(submission, indent=4)\n",
        "save_path = 'submission.json'\n",
        "with open(save_path, 'w') as f:\n",
        "    f.write(submission_object)\n",
        "\n",
        "\n",
        "label_json_path = 'label.json'\n",
        "submission_json_path = 'submission.json'\n",
        "\n",
        "results = evaluate_submission(submission_json_path, label_json_path)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "B6YjbsIxhvYI",
      "metadata": {
        "id": "B6YjbsIxhvYI"
      },
      "outputs": [],
      "source": [
        "# When missing entry in submission file\n",
        "# Ground truth (label.json)\n",
        "label = {\n",
        "    \"file_path\": [\n",
        "        \"book1_page1\",\n",
        "        \"book1_page2\",\n",
        "        \"book1_page3\",\n",
        "        \"book1_page4\",\n",
        "        \"book1_page5\",\n",
        "        \"book1_page6\",\n",
        "        \"book1_page7\"\n",
        "    ],\n",
        "    \"label\": [\n",
        "        \"Si por evitar un pecado mortal\",\n",
        "        \"aveys de poner vuestra vida en pe\",\n",
        "        \"ligro arriesgalda que es el mejor\",\n",
        "        \"empleo que della podeys hazer y\",\n",
        "        \"de vuestra hazienda para este fin en\",\n",
        "        \"redemir cautivos y sacar mugeres\",\n",
        "        \"de pecado dotandolas liberalmen\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "submission = {\n",
        "    \"file_path\": [\n",
        "        \"book1_page1\",\n",
        "        \"book1_page2\",\n",
        "        \"book1_page3\",\n",
        "        \"book1_page5\",\n",
        "        \"book1_page6\",\n",
        "        \"book1_page7\"\n",
        "    ],\n",
        "    \"prediction\": [\n",
        "        \"si por euitar n pecado mortal\",\n",
        "        \"aueys de poner uuestra uida en pe\",\n",
        "        \"ligro arriesgalda que es el mejor\",\n",
        "        \"hazienda para este fin en\",\n",
        "        \"redemir cautiuos y sacar mugeres\",\n",
        "        \"de pecado dotandolas liberalmen\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "with open('label1.json', 'w') as f:\n",
        "    json.dump(label, f, indent=4)\n",
        "\n",
        "with open('submission1.json', 'w') as f:\n",
        "    json.dump(submission, f, indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "go87hzn4hQc6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go87hzn4hQc6",
        "outputId": "cbf6afa9-73f7-419b-827c-50358005bae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: File path 'book1_page4' not found in submission file.\n",
            "{'cer': 0.21238938053097345, 'wer': 0.34146341463414637, 'levenshtein_distance': 6.857142857142857, 'similarity_score': 0.8066665118016189, 'all_levenshtein_distances': [2, 3, 0, 31, 11, 1, 0], 'all_similarity_scores': [0.9491525423728814, 0.9090909090909091, 1.0, 0.0, 0.819672131147541, 0.96875, 1.0]}\n"
          ]
        }
      ],
      "source": [
        "label_json_path = 'label1.json'\n",
        "submission_json_path = 'submission1.json'\n",
        "\n",
        "results = evaluate_submission(submission_json_path, label_json_path)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ece36f95",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
